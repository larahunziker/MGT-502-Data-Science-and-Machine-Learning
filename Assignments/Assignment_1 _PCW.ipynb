{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc4475-7f7d-4457-8762-bb031a0629b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT YOUR LIBRARIES HERE\n",
    "import random\n",
    "\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import prettytable as pt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import (LinearRegression, LogisticRegression,\n",
    "                                  LogisticRegressionCV, Ridge, RidgeCV)\n",
    "from sklearn.metrics import (confusion_matrix, f1_score, mean_absolute_error,\n",
    "                             mean_squared_error, precision_score, r2_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import (LabelEncoder, MinMaxScaler, OneHotEncoder,\n",
    "                                   PolynomialFeatures, StandardScaler)\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35410840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a844a8c0-078c-4946-8927-e570469c601c",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "Welcome to the assignment!\n",
    "\n",
    "You will have to implement regression and classification algorithms, applying these methods to the topics of agriculture, food, water, and health. More precisely, you will try to:\n",
    "\n",
    "- predict crop yields using data on weather and fertilizer use;\n",
    "- predict the potability of water using data on the mineral and micro-organisms content of water.\n",
    "\n",
    "Once you are done you have to submit your notebook here:\n",
    "[https://moodle.epfl.ch/mod/assign/view.php?id=1244180](https://moodle.epfl.ch/mod/assign/view.php?id=1244180)\n",
    "\n",
    "If there is need for further clarifications on the questions, after the assignment is released, we will update this file, so make sure you check the git repository for updates.\n",
    "\n",
    "Good luck!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "306ac928-a1e5-4dd7-8e62-b8108c22e5a9",
   "metadata": {},
   "source": [
    "## Linear regression: predicting crop yields\n",
    "\n",
    "In 2020, between 720 million and 811 million persons worldwide were suffering from hunger (see [SDG Goal 2](https://www.un.org/sustainabledevelopment/hunger/) Zero Hunger). Given the ongoing growth of the world population, it is imperative to comprehend crop yield at a global level in order to tackle food security issues and mitigate the effects of climate change.\n",
    "\n",
    "The Agricultural yield depends on weather conditions (rain, temperature, etc) and fertilizers use. Having precise information regarding the historical crop yield is critical for making informed decisions regarding agricultural risk management and future projections.\n",
    "\n",
    "Some E4S publications on the topic of food:\n",
    "\n",
    "- [Threats to Nitrogen Fertilizer, Opportunities to Cultivate Sustainable Practices?](https://e4s.center/resources/reports/threats-to-nitrogen-fertilizer-opportunities-to-cultivate-sustainable-practices/)\n",
    "- [True cost of food as a lever to transform the Swiss food system](https://e4s.center/resources/reports/true-cost-of-food-as-a-lever-to-transform-the-swiss-food-system/)\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Sustainable_Development_Goal_02ZeroHunger.svg/800px-Sustainable_Development_Goal_02ZeroHunger.svg.png' width='200'>\n",
    "\n",
    "We will use data obtained from the [FAO](http://www.fao.org/home/en/) (Food and Agriculture Organization) and [World Data Bank](https://data.worldbank.org/), and gathered in the [Crop Yield Prediction Dataset](https://www.kaggle.com/datasets/patelris/crop-yield-prediction-dataset).\n",
    "\n",
    "Our goal is to predict the crop yields using the temperature, rain fall, and type of crops.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "783579c9-3e8e-4b44-b95a-58179f897d40",
   "metadata": {},
   "source": [
    "### Question 1: Load and Discover the dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0beccfea-24ca-4c3f-92f1-c5a950b2cbce",
   "metadata": {},
   "source": [
    "- Load the data in a dataframe. The url link is provided below. Display the first 10 observations and the types of data **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87e292-3eed-4193-ba24-60693606b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_yield = 'https://raw.githubusercontent.com/michalis0/MGT-502-Data-Science-and-Machine-Learning/main/data/yield_df.csv'\n",
    "\n",
    "# local_path = '../data/yield_df.csv'\n",
    "yield_df = pd.read_csv(url_yield)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "860b293c",
   "metadata": {},
   "source": [
    "I will start by renaming the columns for improved readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fea1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_df = yield_df.rename(index=str, columns={'year': 'Year', 'hg/ha_yield': 'Yield', 'avg_temp': 'Temperature',\n",
    "                           'pesticides_tonnes': 'Pesticides', 'average_rain_fall_mm_per_year': 'Avg. Rain fall'})\n",
    "display(yield_df.head(10))\n",
    "display(yield_df.dtypes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0916a03-2452-43da-9c5d-c5f43fddd8f2",
   "metadata": {},
   "source": [
    "- Print the list of countries ('Area') and years available in the dataset **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns all the unique (if set) items in the given column\n",
    "\n",
    "def get_col_items_as_list(df, col_name, unique) -> list:\n",
    "    '''\n",
    "    Function that returns all the columns names in a list of a given df\n",
    "    The parameter unique is used to check for unique items in the column\n",
    "    '''\n",
    "    if unique:\n",
    "        return df[col_name].unique().tolist()\n",
    "    else:\n",
    "        return df[col_name].value.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13bb43-fe6f-49ec-b2a4-2faee5cee321",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = get_col_items_as_list(yield_df, 'Area', True)\n",
    "years = get_col_items_as_list(yield_df, 'Year', True)\n",
    "\n",
    "print(f'The countries in the the dataframe are:\\n {countries}')\n",
    "print(f'The years available in the the dataframe are:\\n {years}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c92f5c7-b11c-428b-9c7c-93406aa3f413",
   "metadata": {},
   "source": [
    "- Print the list of 'Item' in the dataset. You should obtain a list of 10 crops, which are among the most consumed in the world **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c32aba-b1fa-46c6-b1e6-0582ab9ca55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = get_col_items_as_list(yield_df, 'Item', True)\n",
    "print(\n",
    "    f'The most consumed crops are: \\n{items}\\nAnd the number of crops are: {len(items)}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0118e44-ca7c-4a81-998f-c8bccf4248e2",
   "metadata": {},
   "source": [
    "- Display summary statistics for the columns: 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp'. How many observations do we have? **1 point**\n",
    "\n",
    "_Hint:_ You can extract the columns 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp' in a new dataframe since we will reuse it in the following questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7462fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a copy of a df with the given columns\n",
    "\n",
    "def get_df_subset(df, cols) -> pd.DataFrame:\n",
    "    return df[cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e212211-7d8d-41e7-a20f-9bcaadf9122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_extract = [\n",
    "    'Yield', 'Avg. Rain fall', 'Pesticides', 'Temperature']\n",
    "yield_subset = get_df_subset(yield_df, columns_to_extract)\n",
    "display(yield_subset.describe())\n",
    "print(\n",
    "    f'We have {yield_subset.shape[0]} observations in our new subset dataframe')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a995d1b-a04b-4e57-bfd9-26db5a4a0f53",
   "metadata": {},
   "source": [
    "- Display a heatmap of the correlation matrix between the columns: 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes','avg_temp' **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatmap(df, title, color_label='', color='RdBu_r', vmin=-1, vmax=1, annot_size=15) -> plt.figure:\n",
    "    '''\n",
    "    Function to get a heatmap with either all columns or a subset of the columns\n",
    "    Returns heatmpap.\n",
    "    '''\n",
    "    sns.set(font_scale=1.1)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(2*df.shape[1], df.shape[1]))\n",
    "    heatmap = sns.heatmap(\n",
    "        df.round(2),\n",
    "        cmap=color,\n",
    "        annot=True,\n",
    "        fmt='.4g',\n",
    "        vmin=vmin, vmax=vmax,\n",
    "        annot_kws={'size': annot_size},\n",
    "        cbar_kws={'label': color_label, 'orientation': 'vertical'})\n",
    "\n",
    "    plt.title(title)\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f577c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmpap_q1 = get_heatmap(yield_subset.corr(), title='Correlation Matrix Crop Parameters', color_label='Correlation')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3fdc8bd",
   "metadata": {},
   "source": [
    "Here we can see that rainfall (mm/year) and Hg/Ha Yield has the lowest correlation of the pairs. The largest positive correlation is between rainfall (mm/year) and average temperature. The larges negative correlation is between average temperature and rainfall (mm/year).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91e4d566-d5e5-4179-8807-cf7f2eb48bf9",
   "metadata": {},
   "source": [
    "- Create a boxplot of the columns: 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp' **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5555a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_box_plot(data: pd.DataFrame, title='Box plot'):\n",
    "    '''\n",
    "    Function that creates a box plot on the given data\n",
    "    Title can be changed\n",
    "    '''\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=data.shape[1], figsize=(15, 5))\n",
    "\n",
    "    # Plot each set of data in a different subplot\n",
    "    for i in range(data.shape[1]):\n",
    "        axs[i].boxplot(data.iloc[:, i], widths=0.6, patch_artist=True,\n",
    "                       boxprops=dict(facecolor='lightblue', color='black'))\n",
    "        axs[i].set_title(f'{data.iloc[:,i].name}')\n",
    "\n",
    "    fig.text(0.04, 0.5, 'Observations', rotation='vertical')\n",
    "    fig.suptitle(title)\n",
    "    # Increase spacing between subplots\n",
    "    fig.subplots_adjust(wspace=0.4)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bae0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot_q1 = get_box_plot(yield_subset, 'Distribution of Crop parameters')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a26e9e8-57bc-4e83-be5d-7a8eecdc52d0",
   "metadata": {},
   "source": [
    "- Create a pairplot of the columns: 'hg/ha_yield', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp' **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f500f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pairplot(data, title='', diag_color='red', hue=None, columns=None):\n",
    "    ''' \n",
    "    Function to get pairplot, input: dataframe, title and diagonal color\n",
    "    Returns plot\n",
    "    '''\n",
    "    if columns:\n",
    "        data=data[columns]\n",
    "\n",
    "    # Customize the diagonal plots to highlight the distribution and setting hue (if given) on given color\n",
    "    plot = sns.pairplot(data, hue=hue, diag_kws={'color': diag_color})\n",
    "    \n",
    "    # Set the title of the plot\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plot.fig.suptitle(title, fontsize=18)\n",
    "    \n",
    "    # Adjust the spacing between the subplots\n",
    "    plot.fig.subplots_adjust(wspace=0.2, hspace=0.2)\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb5c2b1-8ff3-4bf5-96dc-fc09782cf06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_plot_q1 = plot_pairplot(yield_subset, title='Data distribution')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e17bd0b",
   "metadata": {},
   "source": [
    "On the diagonal (with a slight red color) we can see the distribution. All of them are quite skewed either left or right except rainfall (mm/year) which is more equally distributed. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3e878bc-9a34-4875-8771-f6521c2f1b66",
   "metadata": {},
   "source": [
    "- Feel free to pursue your exploration to better understand your dataset. Although not graded, this might help you better understanding the problem and answer the following questions.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7943240",
   "metadata": {},
   "source": [
    "First of all i just wanted to see have all of these paremeters have changed over time. Some of them might have increased a lot the last few years, and can then also give us some information about the parameters respective importance and relationship to later predict our crop yield. Additionally i would like to check whether i have some duplicates in my data, plot its main statistics, and if its a substantial amount it might bias our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ba11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting duplicates\n",
    "duplicates_to_show = yield_df.duplicated(keep=False)\n",
    "duplicates = yield_df.duplicated()\n",
    "duplicate_rows = duplicates[duplicates]\n",
    "\n",
    "# Displaying duplicates\n",
    "display(yield_df.loc[duplicates_to_show])\n",
    "print('Number of duplicates:', duplicates.sum())\n",
    "\n",
    "# Comparing the characteristics of the duplicated with the full data set and a dataset with removed duplicates\n",
    "display('Duplicate dataset', yield_df.loc[duplicates].describe())\n",
    "display('Original dataset', yield_df.describe())\n",
    "\n",
    "yield_no_dup_df = yield_df.drop_duplicates()\n",
    "display('No duplicates dataset', yield_no_dup_df.describe())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aad4fe4b",
   "metadata": {},
   "source": [
    "Our 'No Duplicate' df does not differ a lot, but when we will train a model later, we would put extra emphasis on the values that occur most frequently. We can see that the mean Pesticide $(~37077 > ~34783)$ usage got a bit lower. Because of this extra emphasis and weight to the observations we have duplicates of, i will remove them and continue working on the dataframe without duplicates. So, after discussing with Boris Thurm about these findings, we where a bit unsure how to interpret it, I tried looking up at the original data provider, and it might seem that these might not be duplicates but just approximate for different regions within a country, so I will continue with the assumption that there might be another parameter missing that differentiates these numbers. Thus i will continue with the original dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc60ddce",
   "metadata": {},
   "source": [
    "So let's check the development of the Yield through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700168be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for items ,yield according to year\n",
    "yield_crop_per_year = yield_df.groupby(['Item', 'Year'])[\n",
    "    'Yield'].aggregate('sum').reset_index(name='Yield')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e71fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plotly_plot(df, x, y, title, color=None):\n",
    "    '''\n",
    "    Function that creates a plotly plot on given dataframe, x, y columns and title.\n",
    "    Takes also a color that corresponds to a column, if not given defaults to None. \n",
    "    '''\n",
    "    fig = px.line(df, x=x, y=y,\n",
    "                  color=color, hover_name=y,  hover_data={x: ':.1f', y: ':.1f'})\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=x,\n",
    "        yaxis_title=y,\n",
    "        font=dict(\n",
    "            family='Times New Roman',\n",
    "            size=10,\n",
    "            color='Black'\n",
    "        )\n",
    "    )\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_through_time = get_plotly_plot(\n",
    "    yield_crop_per_year, 'Year', 'Yield', 'Crop yield for each crop type over time', 'Item')\n",
    "crops_through_time.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8bb7b87",
   "metadata": {},
   "source": [
    "We can see that the yield is steadily increasing for all crop types (items)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for items ,yield according to year\n",
    "yield_persticides_per_year = yield_df.groupby(\n",
    "    ['Item', 'Year'])['Pesticides'].aggregate('sum').reset_index(name='Pesticides')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef5e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesticides_through_time = get_plotly_plot(\n",
    "    yield_persticides_per_year, 'Year', 'Pesticides', 'Pesticides for each crop through time', 'Item')\n",
    "pesticides_through_time.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91cfdeda",
   "metadata": {},
   "source": [
    "The pesticide usage has heavily increased!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d84fb171",
   "metadata": {},
   "source": [
    "We could also see that the data was heavily skewed, i will try to do a log transformation on the most skewed columns (Yield and Pesticides), and see if that has any impact on our predictions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdddbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_subset_norm = yield_subset.copy()\n",
    "yield_subset_norm['Yield'] = np.log(yield_subset_norm['Yield'])\n",
    "yield_subset_norm['Pesticides'] = np.log(yield_subset_norm['Pesticides'])\n",
    "display(yield_subset_norm)\n",
    "box_plot_q1_norm = get_box_plot(yield_subset_norm, 'Log normalized data distribution')\n",
    "pair_plot_q1 = plot_pairplot(yield_subset_norm, 'Log normalized data distribution')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "241ea7ab",
   "metadata": {},
   "source": [
    "The two plots above clearly shows that the distribution is not as aggressive anymore. I will investigate whether the log transformed data performs better in the coming question."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9741f056-f011-469c-9527-d1d016ddce83",
   "metadata": {},
   "source": [
    "### Question 2: Multivariate regression\n",
    "\n",
    "We will try to predict the crop yields (column 'hg/ha_yield') using as features: 'Item', 'average_rain_fall_mm_per_year', 'pesticides_tonnes', 'avg_temp'\n",
    "\n",
    "- Extract your features and outcome **1 point**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36f55bc4",
   "metadata": {},
   "source": [
    "What we are trying to predict can be explained by the following equation:\n",
    "\n",
    "$$Yield = w_0 + w_1 * Item + w_2 * Rainfall + w_3 * Pesticides + w_4 * Temperature + \\epsilon_i$$\n",
    "Where $w_i$ represents the different weights we assign to the given parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f218896-30f9-41d9-95a8-7550ab0fcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Item', 'Avg. Rain fall',\n",
    "            'Pesticides', 'Temperature']\n",
    "\n",
    "df_multi = get_df_subset(yield_df, features)\n",
    "\n",
    "\n",
    "X = df_multi\n",
    "y = yield_df['Yield']\n",
    "\n",
    "# Keeping the log transformed data to check whether that can have an impact on the results later on\n",
    "X_log = yield_subset_norm.copy()\n",
    "X_log['Item'] = df_multi['Item'].copy()\n",
    "X_log.drop(columns='Yield', inplace=True)\n",
    "y_log = yield_subset_norm['Yield']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fccaf94d-c35f-46b8-ae64-456446f93bf7",
   "metadata": {},
   "source": [
    "- Split between training and test set **1 point**\n",
    "\n",
    "_Note_: Use as option: `test_size=0.2`, `random_state=42`, `shuffle=True`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc8bd9-7d91-4b60-a545-dcc254897368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9511b15e-2147-48c7-82e0-24bf45bd194e",
   "metadata": {},
   "source": [
    "- Encode the column 'Item' using `LabelEncoder` **1 point**\n",
    "\n",
    "_Note_: After training your encoder, you need to transform the values of both the training and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155159a-d993-4dca-8320-5e2a39725929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(X_train[['Item']])\n",
    "\n",
    "# Extract the column of interest\n",
    "Item = X_train[['Item']].values.ravel()\n",
    "Item_test = X_test[['Item']].values.ravel()\n",
    "\n",
    "# Define the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder\n",
    "le.fit(Item)\n",
    "\n",
    "# Transform the train and the test set\n",
    "X_train = X_train.assign(Item=le.transform(Item))\n",
    "X_test = X_test.assign(Item=le.transform(Item_test))\n",
    "print(X_train[['Item']])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1c6a1b9",
   "metadata": {},
   "source": [
    "Now we have transformed the categorical variables by encoding the different 'items'.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99c27197-47b0-4d46-a65b-8226d0accef8",
   "metadata": {},
   "source": [
    "- Rescale your features using `MinMaxScaler` **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b429b73-27ca-4816-9377-02114e939a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaler(X_train:list, X_test:list, scaler):\n",
    "    '''\n",
    "    Function that returns scaled values for the input of X's and Y's, with the given scaler\n",
    "    Returns a tuple with the scaled X,Y values\n",
    "    '''\n",
    "    scaler = scaler()\n",
    "    scaler.fit(X_train)  # Fitting the scaler\n",
    "\n",
    "    # Transform the train and the test set\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "min_max_scaler = MinMaxScaler  # Instantiating the scaler\n",
    "X_train, X_test = get_scaler(X_train, X_test, min_max_scaler)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d62901f2-e2c9-46f9-bffe-0d0f431a0f1d",
   "metadata": {},
   "source": [
    "- Build and train a multivariate linear regression model **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac40095-701c-47d3-81ca-06e6740bd439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b52fa49c-f2a9-4c43-8170-80ef1d6f3326",
   "metadata": {},
   "source": [
    "- What is the $R^2$, mean absolute error, and mean square error on the training set? On the test set? What do you think? **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae_mse_r2(x, y, model) -> tuple:\n",
    "    '''\n",
    "    Function that given a model calculates the MAE, MSE and R-squared rounded with 3 decimals\n",
    "    '''\n",
    "    # Model predictions\n",
    "    pred = model.predict(x)\n",
    "\n",
    "    mae = mean_absolute_error(y, pred).round(3)\n",
    "    mse = mean_squared_error(y, pred).round(3)\n",
    "    r2 = r2_score(y, pred).round(2)\n",
    "\n",
    "    return mae, mse, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78685c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mae_mse_r2_df(X_train, y_train, X_test, y_test, model, column_name) -> pd.DataFrame:\n",
    "    '''\n",
    "    Function that returns a dataframe with the key statistical features (MAE, MSE and R-squared) on training and test set\n",
    "    Uses the helper function get_mae_mse_r2()\n",
    "    '''\n",
    "\n",
    "    mae_train, mse_train, r2_train = get_mae_mse_r2(X_train, y_train, model)\n",
    "    mae_test, mse_test, r2_test = get_mae_mse_r2(X_test, y_test, model)\n",
    "\n",
    "    stat_tests_labels = ['MAE Train',\n",
    "                  'MAE Test',\n",
    "                  'MSE Train',\n",
    "                  'MSE Test',\n",
    "                  'R\\u00b2 Train',\n",
    "                  'R\\u00b2 Test']\n",
    "\n",
    "    df = pd.DataFrame([mae_train, mae_test, mse_train, mse_test, r2_train, r2_test],\n",
    "                      index=stat_tests_labels,\n",
    "                      columns=[column_name])\n",
    "    \n",
    "    # Changing the format and limiting to 2 decimals\n",
    "    pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_var_stats_df = get_mae_mse_r2_df(X_train, y_train, X_test, y_test, model, 'Multivariate regression')\n",
    "display(multi_var_stats_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "524c5e07",
   "metadata": {},
   "source": [
    "Here we can see the statistical performance of our values with the label encoder. As we know the label encoder gives each crop type its own value. Now we can check that the categorical values actual was transformed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2924bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(np.unique(le.transform(Item)))\n",
    "display(np.unique(X_train.T[0]))\n",
    "display(len(np.unique(X_train.T[0])) == np.unique(le.transform(Item)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "256fa011",
   "metadata": {},
   "source": [
    "At least to me it's not intuitive that we will have all the different crop types in the same dimension. Here we can see that each is mapped in the range of [0,1] with a 0.11111111 interval. I'm just thinking out loud here, but how can the model build something useful on the fact that Soybean is 0.11111111 larger than for instance Sorghum. I would assume that having one column for each crop type would provide our model more predictive power."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28012dc4",
   "metadata": {},
   "source": [
    "So to conclude, overall the $R^2$ is very low, which means that our models has a bad fit. Our model has a $R^2$ close to $0$, which means that our model is nearly better to predict than taking the average of our observations. We can also see that the $R^2$ on the training set is in absolute terms $0.01$ lower than the test set. This difference is very low and can just be explained by randomness. Both the $MAE$ and $MSE$ is slightly bigger on the test set.\n",
    "\n",
    "It seems counter-intuitive that the $R^2$ is bigger on the test set when the $MSE$ and $MAE$ is larger as well. The reason for this is that $TSS\\text{ (total sum of squares)}$ is relatively smaller than the $RSS\\text{ (residual sum of squares)}$ in the test set compared to the training set.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da5ab892",
   "metadata": {},
   "source": [
    "#### Question 2.1: Multivariate regression with log transformed data\n",
    "It would be interesting to see how the log transformed data will perform in this matter. So the following code does exactly the same steps but with the log-transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Splitting train and test set\n",
    "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(\n",
    "    X_log, y_log, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# 2. Encoding the categorical data\n",
    "\n",
    "Item = X_train_log[['Item']].values.ravel()\n",
    "Item_test_log = X_test_log[['Item']].values.ravel()\n",
    "le = LabelEncoder()\n",
    "le.fit(Item)\n",
    "X_train_log = X_train_log.assign(Item=le.transform(Item))\n",
    "X_test_log = X_test_log.assign(Item=le.transform(Item_test_log))\n",
    "\n",
    "# 3. Scaling data\n",
    "X_train_log, X_test_log = get_scaler(X_train_log, X_test_log, min_max_scaler)\n",
    "\n",
    "# 4. Building and train model\n",
    "model_log = LinearRegression()\n",
    "model_log.fit(X_train_log, y_train_log)\n",
    "\n",
    "# 5. Testing model\n",
    "multi_var_stats_df_log = get_mae_mse_r2_df(X_train_log, y_train_log, X_test_log, y_test_log, model_log, 1)\n",
    "\n",
    "multi_var_comparison = multi_var_stats_df.copy()\n",
    "multi_var_comparison.rename(columns={1: 'Absolute'}, inplace=True)\n",
    "multi_var_comparison['Multivariate regression (Log transformed)'] = multi_var_stats_df_log\n",
    "display(multi_var_comparison)\n",
    "display(multi_var_comparison.dtypes)\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72fc84c1",
   "metadata": {},
   "source": [
    "We can see that the $R^2$ is slightly better for the log transformed data, but when some data is in log and other i absolute numbers, it's harder to interpret."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44ee7320-d129-4cdc-975c-4c682b4ad351",
   "metadata": {},
   "source": [
    "### Question 3: Polynomial features regression\n",
    "\n",
    "We will try to improve the quality of our prediction using `PolynomialFeatures`.\n",
    "\n",
    "- Write a function that is using as inputs the degree of polynomial features (an integer), the training and test set (for your features and outcome), and return the $R^2$, mean absolute error, and mean square error on the training and on the set of a polynomial feature regression **3 points**\n",
    "\n",
    "_Hint:_ You do not need to include in your function the splitting, encoding and scaling since we will reuse the ones set created before (as before). Your function should transform your training and test set to integrate polynomial features, then build and train your model, before calculating the various error metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poly_transform(X_train, X_test, degrees) -> tuple:\n",
    "    '''\n",
    "    Helper function to get polynomial transformation returns tuple with train and test set\n",
    "    '''\n",
    "    model_poly = PolynomialFeatures(degrees)\n",
    "    X_train_poly = model_poly.fit_transform(X_train)\n",
    "    X_test_poly = model_poly.transform(X_test)\n",
    "    return X_train_poly, X_test_poly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d9b98-d3c6-4ca7-b934-7fe7e48bbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_poly_stats(degrees, X_train, y_train, X_test, y_test, additonal_title='') -> pd.DataFrame:\n",
    "    '''\n",
    "    Function that create model using get_poly_transform() and trains the model with the given data\n",
    "    Returns a dataframe with  key statistical characteristics s.a.a MAE, MSE, R^2 using get_mae_mse_r2_df()\n",
    "    '''\n",
    "\n",
    "    X_train_poly, X_test_poly = get_poly_transform(\n",
    "        X_train, X_test, degrees)\n",
    "\n",
    "    # Setting up the model\n",
    "    model_poly = LinearRegression(fit_intercept=False)\n",
    "\n",
    "    # Fit\n",
    "    model_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Now we can reuse the previous made functions to get the MAE, MSE and R^2\n",
    "    return get_mae_mse_r2_df(X_train_poly, y_train, X_test_poly, y_test, model_poly, f'Poly Degree: {degrees} {additonal_title}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28d9dab7-aabd-4198-8306-f434f5f949e3",
   "metadata": {},
   "source": [
    "- What are the the $R^2$, mean absolute error, and mean square error on the training and on the set of a polynomial features regression with degree = 3? With degree = 7? **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e055746-5a5c-4381-b662-ed548e2cf503",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_stats_df_3 = get_poly_stats(3, X_train, y_train, X_test, y_test)\n",
    "poly_stats_df_7 = get_poly_stats(7, X_train, y_train, X_test, y_test)\n",
    "\n",
    "display(poly_stats_df_3)\n",
    "display(poly_stats_df_7)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04100b38-57e6-46c9-9a63-43c141d4b299",
   "metadata": {},
   "source": [
    "- Plot the evolution of the MSE on the training set for a polynomial feature regression model when the degree goes from 2 to 10. On the same figure, plot the MSE on the test set for a polynomial feature regression model, when the degree goes from 2 to 10. Which degree would you choose and why? **2 points**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c181d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_to_ten = np.linspace(1, 10, num=10, dtype='int')\n",
    "df_stats_poly_one_ten = pd.DataFrame([])\n",
    "df_stats_poly_one_ten_log = pd.DataFrame([])\n",
    "\n",
    "# Looping from 1-10 to get the stats for each polynomial degree\n",
    "for i in one_to_ten:\n",
    "    df_stats_poly_one_ten[f'Polynomial degree: {i}'] = get_poly_stats(\n",
    "        i, X_train, y_train, X_test, y_test)\n",
    "    # Doing the same with the log transformed data to check if it makes a difference\n",
    "    df_stats_poly_one_ten_log[f'Polynomial degree: {i} (Log)'] = get_poly_stats(\n",
    "        i, X_train_log, y_train_log, X_test_log, y_test_log)\n",
    "\n",
    "display(df_stats_poly_one_ten)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f84f16ac",
   "metadata": {},
   "source": [
    "Now we have a dataframe with all the data we need to plot the development. I will create a plot for the $MSE$, to see more easily compare the log transformed data with the .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752710bf-a720-41d9-92c7-d196922ad96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_plot_with_traces(df: pd.DataFrame, y_list, title) -> go.Figure:\n",
    "    '''\n",
    "    Function that returns a graph with multiple traces, input is a dataframe and a list of the y-traces to be plotted along with title\n",
    "    '''\n",
    "    # Define the x and y values\n",
    "    x = df.columns.values\n",
    "    trace_list = []\n",
    "\n",
    "    for y in y_list:\n",
    "        trace = go.Scatter(\n",
    "            x=x, y=y.values,\n",
    "            mode='lines+markers',\n",
    "            name=y.name,\n",
    "            hovertemplate='Polynomial degree: %{x}<br>%{y}',\n",
    "            marker=dict(size=8),\n",
    "            line=dict(\n",
    "                width=2,\n",
    "            )\n",
    "        )\n",
    "        trace_list.append(trace)\n",
    "\n",
    "    # Add axis labels and a title\n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        xaxis=dict(title='Polynomial degrees'),\n",
    "        yaxis=dict(title='R\\u00b2'),\n",
    "        legend=dict(x=1, y=-0.2),\n",
    "        autosize=True\n",
    "    )\n",
    "\n",
    "    # Create a figure\n",
    "    return go.Figure(data=trace_list, layout=layout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8632c4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the x and y values\n",
    "y1 = df_stats_poly_one_ten.iloc[-4,1:]  # Getting the fourth last row : MSE train\n",
    "y2 = df_stats_poly_one_ten.iloc[-3,1:]  # Getting the third last row : MSE test\n",
    "\n",
    "fig = get_plot_with_traces(df_stats_poly_one_ten.iloc[:, 1:], y_list=[\n",
    "#fig = get_plot_with_traces(df_stats_poly_one_ten, y_list=[\n",
    "                           y1, y2], title='MSE for different polynomial degrees')\n",
    "fig.update_layout(yaxis=dict(title='MSE'))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389fd06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the x and y values\n",
    "y_log_1 = df_stats_poly_one_ten_log.iloc[-4,1:]  # Getting the fourth last row : MSE train\n",
    "y_log_2 = df_stats_poly_one_ten_log.iloc[-3,1:]  # Getting the third last row : MSE test\n",
    "\n",
    "fig_log = get_plot_with_traces(df_stats_poly_one_ten_log.iloc[:, 1:], y_list=[\n",
    "                           y_log_1, y_log_2], title='MSE for different polynomial degrees (log transformed)')\n",
    "fig_log.update_layout(yaxis=dict(title='MSE'))\n",
    "fig_log.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be7ee539",
   "metadata": {},
   "source": [
    "Here we can clearly see that the $R^2$ increases a lot for every iteration towards a polynomial degree of 6. After 6, it diverges as our model is getting too 'specialized' and lacking generalization. But when our features get larger than the number of observation there's an increasing chance of overfitting. \n",
    "\n",
    "Let's say that:\n",
    "$$\\text{d = degree, m = features, n=observations, and k = \"new\" number of features}$$\n",
    "We know that the amount of polynomial features (k) are given as:\n",
    "$$ k =\\begin{pmatrix}d+m\\\\d\\end{pmatrix} = \\frac{(d + m)!}{(d! * m!)}.$$\n",
    "\n",
    "\n",
    "\n",
    "Scikit uses the L-FBGS algorithm with time complexity  $O(k*m)$. Where $m$ is a number describing the memory (typically 5-30), but the essence is that the running time is highly dependent on number of features ($k$). \n",
    "I would therefor choose 6, which matches the \"elbow\" of $MSE$ ('MSE for different polynomial degrees') of the graph plotted earlier. With $d=6$ and $m=4$ we get to following amount of new features ($k$), which should be computational \"feasible\".\n",
    "$$\\text{Polynomial Degree} = 6$$\n",
    "$$ k =\\begin{pmatrix}6+4\\\\6\\end{pmatrix} = \\frac{(6 + 4)!}{(6! * 4!)} = 210$$\n",
    "\n",
    "\n",
    "Sources:\n",
    "- http://www.people.vcu.edu/~ysong3/lecture8.pdf\n",
    "- https://aip.scitation.org/doi/pdf/10.1063/1.4995124\n",
    "- https://en.wikipedia.org/wiki/Limited-memory_BFGS\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1997ab23",
   "metadata": {},
   "source": [
    "For curiosity sake, and since I have made  a generic function to plot several traces, we can easily plot the $R^2$ of both our log and \"normal\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename for readability in graph\n",
    "\n",
    "y1 = df_stats_poly_one_ten.iloc[-2]  # Getting the second last row : R^2 train\n",
    "y2 = df_stats_poly_one_ten.iloc[-1]  # Getting the  last row : R^2 test\n",
    "y3 = df_stats_poly_one_ten_log.iloc[-1]\n",
    "y4 = df_stats_poly_one_ten_log.iloc[-2]\n",
    "\n",
    "df_stats_poly_one_ten_log.rename(\n",
    "    index={'R\\u00b2 Train': 'R\\u00b2 Train (Log)'}, inplace=True)\n",
    "df_stats_poly_one_ten_log.rename(\n",
    "    index={'R\\u00b2 Test': 'R\\u00b2 Test (Log)'}, inplace=True)\n",
    "\n",
    "# Create a list to feed the plot function for the traces i want to display\n",
    "y_values_to_be_traced = [y1, y2, y3, y4]\n",
    "\n",
    "r2_plot_comparison = get_plot_with_traces(df_stats_poly_one_ten, y_list=y_values_to_be_traced,\n",
    "                                          title='R\\u00b2 for different polynomial degrees (including log transformed)')\n",
    "r2_plot_comparison.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6ad3c44",
   "metadata": {},
   "source": [
    "From this graph we can see that the log normalized data doesn't really outperform the absolute values even though it performs slightly better except at polynomial degree 4, where they are approximately the same. For simplicity, and easier interpretation i will remain with the original data format."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5443919d-7150-49c6-8efe-6421b6ff65f5",
   "metadata": {},
   "source": [
    "### Question 4: Ridge and cross-validation\n",
    "\n",
    "- Build, train, and evaluate a polynomial features regression model, with Ridge regularization, and cross validation. For number of degree, select the one that you picked before. How does your new model compares to your previous one? **3 points**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ff6d1-f084-4a14-908d-bc3ac129cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use helper function to get poly transformation for the chosen polynomial degrees\n",
    "X_train_poly_ridge, X_test_poly_ridge = get_poly_transform(X_train, X_test, 6)\n",
    "\n",
    "# Set up the model\n",
    "ridge_model = Ridge(alpha=1, fit_intercept=False, max_iter=1000)\n",
    "ridge_model_zero = Ridge(alpha=0, fit_intercept=False, max_iter=1000)\n",
    "\n",
    "# Use fit\n",
    "ridge_model.fit(X_train_poly_ridge, y_train)\n",
    "ridge_model_zero.fit(X_train_poly_ridge, y_train)\n",
    "\n",
    "# Getting the key stats df\n",
    "ridge_stats = get_mae_mse_r2_df(\n",
    "    X_train_poly_ridge, y_train, X_test_poly_ridge, y_test, ridge_model, 'Ridge Model (Alpha=1)')\n",
    "\n",
    "ridge_stats_zero = get_mae_mse_r2_df(\n",
    "    X_train_poly_ridge, y_train, X_test_poly_ridge, y_test, ridge_model_zero, 'Ridge Model (Alpha=0)')\n",
    "\n",
    "# Displaying with 2 decimals in string format for readability\n",
    "display(ridge_stats)\n",
    "display(ridge_stats_zero)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eb5cadc",
   "metadata": {},
   "source": [
    "The results where not very impressive by the ridge regularization, but ridge punishes the test data quite substantially since the regularization parameter $\\alpha$ has a large impact on $MAE$ and $MSE$ (in the test data). When `alpha = 0`, the objective is equivalent to ordinary least\n",
    "squares. Thus when $\\alpha$ is approaching $0$, our $R^2$ approaches $0.77$ which is what we got with our 7 degree polynomial prediction.\n",
    "\n",
    "Now we can compare these statistics with the previous created df called `df_stats_poly_one_ten` where we have the performance metrics for $\\text{Polynomial Degree}: 1-10$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827bfcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_and_ridge_comparison_df = df_stats_poly_one_ten.copy()\n",
    "poly_and_ridge_comparison_df[ridge_stats.columns[0]] = ridge_stats\n",
    "poly_and_ridge_comparison_df[ridge_stats_zero.columns[0]] = ridge_stats_zero\n",
    "display(poly_and_ridge_comparison_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a27ebe2",
   "metadata": {},
   "source": [
    "As we saw above, the results have not improved, in addition to the way $\\alpha$ punishes it it might be that the way we transformed our categorical data with LabelEncoding is not the optimal.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "958e9fd6",
   "metadata": {},
   "source": [
    "Now let's use K-fold cross validation and see if our score improves. Just to showcase the best alpha, we can use the parameter `alphas` for the cross-validation to find the best alpha. The parameter has to be $>0$, so we can start with something really small such as $1*10^{-10}$ and create a evenly spaced interval up to $100$. We can also report the best $\\alpha$ to verify our findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3435df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model\n",
    "ridge_cv_model = RidgeCV(alphas=np.linspace(\n",
    "    1e-10, 100, 20), cv=5, fit_intercept=False)\n",
    "\n",
    "# Use fit and the previous created X-values, the y stays the same\n",
    "ridge_cv_model.fit(X_train_poly_ridge, y_train)\n",
    "\n",
    "ridge_cv_stats = get_mae_mse_r2_df(\n",
    "    X_train_poly_ridge, y_train, X_test_poly_ridge, y_test, ridge_cv_model, 'Ridge-CV Model')\n",
    "\n",
    "display(ridge_cv_stats)\n",
    "print(f'Alpha used: {ridge_cv_model.alpha_}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a5b9301",
   "metadata": {},
   "source": [
    "Again, our results did not improve, and our model chose the smallest $\\alpha = 1*10^{-10}$, which means that we are (almost) not regularizing at all, and our model objective is equivalent to ordinary least squares demonstrated by our results in the `Multivariate LinearRegression`... So we might need to encode our categorical data better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f787c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Using the previous created function to display in nicer format\n",
    "display(poly_and_ridge_comparison_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9726e7f3-6c1d-4091-96d6-62cf5ada771e",
   "metadata": {},
   "source": [
    "### Question 5: One-Hot encoding\n",
    "\n",
    "We will check how the encoding influenced our results.\n",
    "\n",
    "- Split your original dataset between training and test set (using the same parameters as in Question 2). This time, encode the column 'Item' using `OneHotEncoder`. Finally, rescale your features. **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc3a22-a1fa-4c03-a505-fbb3b4413afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to do One-Hot encoding, takes a dataframe and the column to encode\n",
    "# Returns the new dataframe\n",
    "\n",
    "def get_ohe(df, column) -> pd.DataFrame:\n",
    "    '''\n",
    "    Function that takes a dataframe and one-hot encodes the given column\n",
    "    '''\n",
    "    ohe = OneHotEncoder()  # Instantiating the OneHotEncoder (ohe)\n",
    "    ohe.fit(df[[column]])  # Fitting the ohe on the given column\n",
    "\n",
    "    # Transforming the given column into a one-hot encoded matrix\n",
    "    ohm = ohe.transform(df[[column]]).toarray()\n",
    "    one_hot_df = pd.DataFrame(  # Creating a new DataFrame with the one-hot encoded matrix and column names\n",
    "        ohm, columns=ohe.get_feature_names_out([column]))\n",
    "\n",
    "    one_hot_df = one_hot_df.reset_index(drop=True)\n",
    "    # Concatenate the one-hot encoded DataFrame with the original DataFrame\n",
    "    df_ret = pd.concat([df.reset_index(drop=True), one_hot_df], axis=1)\n",
    "\n",
    "    df_ret.drop(column, axis=1, inplace=True)  # Drop the original column\n",
    "    return df_ret\n",
    "\n",
    "\n",
    "# Creating a copy of our X's to keep things clean\n",
    "X_ohe = X.copy()\n",
    "\n",
    "# Splitting data before encoding to avoid data leakage\n",
    "X_train_ohe, X_test_ohe, y_train_ohe, y_test_ohe = train_test_split(\n",
    "    X_ohe, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Calling the One-Hot encoding function\n",
    "X_train_ohe = get_ohe(X_train_ohe, 'Item')\n",
    "X_test_ohe = get_ohe(X_test_ohe, 'Item')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dca5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now we can rescale our features using our previously  defined MinMaxScaler function\n",
    "min_max_scaler = MinMaxScaler\n",
    "X_train_ohe, X_test_ohe = get_scaler(X_train_ohe, X_test_ohe, min_max_scaler)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "562ea67b-63b7-4e3e-81b2-514f592c277e",
   "metadata": {},
   "source": [
    "- Build, train, and evaluate a polynomial features regression model, with the same number of degrees as before, but this time with the one-hot encoded data. How does your model compares to the polynomial features regression model (Question 3)? **2 points**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e3231ae",
   "metadata": {},
   "source": [
    "Now, with the one-hot encoder we have added a lot of new features to our model, which increases the time complexity of our model. Hence, we either could (1) reduce the number of features, by removing those with little correlation, (2) reduce the number of polynomial degrees or (3) reduce the sample size. I will try to discover a combination of these strategies. So the number of features will now be:\n",
    "$$\\text{Polynomial Degree} = 6$$\n",
    "$$ k =\\begin{pmatrix}6+13\\\\6\\end{pmatrix} = \\frac{(19)!}{(6! * 13!)} = 27132$$\n",
    "which is more than 100 times larger than our previous model with 220 features. So the first thing i tried was to use the `RFE` which reduces the size of the features by excluding the least important features. I will build the degrees up and see how much is tolerated in regards to time spent...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19c783-76c6-4a18-9282-10cc40fb1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform feature selection on training data using RFE\n",
    "model = LinearRegression()\n",
    "\n",
    "# Showcasing poly degree 5 and 50 features\n",
    "rfe = RFE(model, n_features_to_select=50)\n",
    "X_train_reduced = rfe.fit_transform(X_train_ohe, y_train_ohe)\n",
    "ohe_poly_selected_df = get_poly_stats(5, X_train_reduced,  y_train_ohe, rfe.transform(X_test_ohe), y_test_ohe, additonal_title='- OHE (with 50 selected features)')\n",
    "ohe_poly_selected_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7407a4f",
   "metadata": {},
   "source": [
    "\n",
    "I found that keeping 50 features and using 5 degree ran in 1.75 minutes and gave an $R^2=0.84$ which is quite a lot better than our polynomial feature model with the same amount of degrees which gave: $PolyModel(5)=>R^2=0,47$. I tried playing around with degree 6 on the one-hot encoded data, but i had to reduce the features to the point where it performed poorer than the 5-degree model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a072df",
   "metadata": {},
   "source": [
    "Another strategy would be to reduce the training set and see if we could keep the polynomial degree. Intuitively this would not reduce the running time that much, since it's the total amount of features that really punishes the running time. But let's try to see if we can do degree 6 by reducing both the set we built our model on and reduce the number of features. I tried by reducing the training set by 50% and only keep the top 10 features. It should run in a little over a minute..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8dfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reducing the sets\n",
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(X_ohe, y, train_size=0.5, random_state=42)\n",
    "X_train_ohe_small, X_test_ohe_small, y_train_ohe_small, y_test_ohe_small = train_test_split(X_train_small, y_train_small, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Calling the One-Hot encoding function\n",
    "X_train_ohe_small = get_ohe(X_train_ohe_small, 'Item')\n",
    "X_test_ohe_small = get_ohe(X_test_ohe_small, 'Item')\n",
    "\n",
    "# Now we can rescale our features using our previously  defined get_scaler function\n",
    "min_max_scaler = MinMaxScaler\n",
    "X_train_ohe_small, X_test_ohe_small = get_scaler(X_train_ohe_small, X_test_ohe_small, min_max_scaler)\n",
    "\n",
    "# Reducing the amount of features\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "X_train_ohe_small = rfe.fit_transform(X_train_ohe_small, y_train_ohe_small)\n",
    "\n",
    "# Testing model and getting results\n",
    "ohe_poly_double_reduced_df = get_poly_stats(6, X_train_ohe_small,  y_train_ohe_small, rfe.transform(X_test_ohe_small), y_test_ohe_small, additonal_title=' (50 selected features and reduced training set)')\n",
    "ohe_poly_double_reduced_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c110d8f8",
   "metadata": {},
   "source": [
    "This should run in under a minute, and it gives an $R^2=0.77$. Reducing the data that the model get to train on seems not to work very well. So to sum up, lets compare the best scoring model here with the one we obtained in Question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106cab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_comparison_df = pd.concat([poly_and_ridge_comparison_df.iloc[:,4], ohe_poly_selected_df], axis=1)\n",
    "display(encoder_comparison_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1970bf20",
   "metadata": {},
   "source": [
    "We see that the one-hot encoder with 50 of the \"best\" features on polynomial degree 5 outperforms the one obtained in Q3. So - the `OneHotEncoder` performs much better than the `LabelEncoder`, and the Ridge and RidgeCV model with the LabelEncoded values of `Item`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d08235a6-27ec-45b7-9adc-0eea440b6b02",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Access to safe drinking-water is essential to health, a basic human right and a component of effective policy for health protection. However, for a least 3 billion people, the quality of the water they depend on is unknown due to a lack of monitoring (see [SDG Goal 6](https://sdgs.un.org/goals/goal6) 'Ensure availability and sustainable management of water and sanitation for all').\n",
    "\n",
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Sustainable_Development_Goal_6.png/800px-Sustainable_Development_Goal_6.png' width='200'>\n",
    "\n",
    "We will use data from the [Water Quality](https://www.kaggle.com/datasets/mssmartypants/water-quality) dataset to try to predict whether the water is safe to drink depending on the concentration of various minerals and microorganisms. Check the webpage to read a description of the features and get a better understanding of our problem.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c15fbefb-e6b7-47ad-aaf0-d411c82a84f4",
   "metadata": {},
   "source": [
    "### Question 6: Load and Discover the dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e484596-0a73-4b6a-a5c5-8a8cd02f8ac2",
   "metadata": {},
   "source": [
    "- Load the data in a dataframe. The url link is provided below. Display the first 10 observations and the types of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b92e6a4-30b0-44b4-b986-9b5d1c472842",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_water = 'https://raw.githubusercontent.com/michalis0/MGT-502-Data-Science-and-Machine-Learning/main/data/waterQuality1.csv'\n",
    "water_df = pd.read_csv(url_water)\n",
    "\n",
    "display(water_df.head(10))\n",
    "display(water_df.dtypes)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61c68ed6-2ecc-4c1a-9dad-f089e34e532d",
   "metadata": {},
   "source": [
    "- Display summary statistics of your dataset and a heatmap of your correlation matrix **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1128ae7-344f-4b76-ac8c-064fa1ffb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(water_df.describe())\n",
    "heat_map_q6 = get_heatmap(water_df.corr(), annot_size=30, title='Correlation Matrix')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37f1fb5b-db18-42f5-ac79-62e80034cd77",
   "metadata": {},
   "source": [
    "- Create a pairplot including the columns 'arsenic', 'cadmium', 'chromium', 'copper', 'bacteria', 'viruses', 'lead', 'nitrates', 'mercury'; and color by the class 'is_safe' **1 points**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8185272-0722-4ae7-921e-8e6f139a0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Features and outcome \n",
    "cols_classification = ['arsenic', 'cadmium', 'chromium', 'copper',\n",
    "                       'bacteria', 'viruses', 'lead', 'nitrates', 'mercury', 'is_safe']\n",
    "\n",
    "# Getting subset\n",
    "df_water_subset = get_df_subset(water_df, cols_classification)\n",
    "\n",
    "# Creating pairplot\n",
    "water_pair_plot = plot_pairplot(\n",
    "    data=water_df, title='Water Pairplot', hue='is_safe', columns=cols_classification)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42054742-c2fb-4976-b401-ea6830ea833f",
   "metadata": {},
   "source": [
    "- Feel free to pursue your exploration to better understand your dataset. Although not graded, this might help you better understanding the problem and answer the following questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a232384",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(water_df[water_df < 0].count())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5af9ceaf",
   "metadata": {},
   "source": [
    "I assume that we cannot have negative values for ammonia, so i will remove these 10 rows. I noticed this at the end, and it changed my results a bit for Question 7-10. All the other features are above or equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b996c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "water_df.drop(water_df[water_df['ammonia'] < 0].index, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3071c9e-1801-4e27-9a4c-8893ac08ef03",
   "metadata": {},
   "source": [
    "### Question 7: Preprocessing\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6522cf94-1f4f-497e-9015-d60f143a47e4",
   "metadata": {},
   "source": [
    "We will try to predict the class 'is_safe', using all the other features.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb8282bf-987f-4409-baaf-39610e66712b",
   "metadata": {},
   "source": [
    "- Extract your features and outcome. How many observations do we have of class 0 and of class 1? **1 point**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6525af5b",
   "metadata": {},
   "source": [
    "I assume by saying all the other features, it's meant that we shall use all columns except 'is_safe'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218d4647-0200-4998-8b5d-5de08fe181a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outcome label\n",
    "outcome_q7 = 'is_safe'\n",
    "\n",
    "# All features without is_safe\n",
    "feature_df = water_df.drop(columns={'is_safe'}).copy()\n",
    "features_classification = feature_df.columns.tolist()\n",
    "\n",
    "# X and y\n",
    "X_class = feature_df\n",
    "y_class = water_df[outcome_q7]\n",
    "\n",
    "feature_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b67d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class.value_counts().plot.bar(color=['purple', 'blue'], grid=False)\n",
    "plt.ylabel('Number of observations')\n",
    "plt.title('Number of observations of each class in the wine dataset')\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f'Unsafe: {y_class.value_counts()[0]}, Safe: {y_class.value_counts()[1]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37201f5c",
   "metadata": {},
   "source": [
    "We have 7076 unsafe (class 0) and 910 safe (class 1) observations. We see that we have a heavy imbalance in our data, but since we care more about the characteristics of unsafe water, this might be alright."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d39e9c21-ba17-4627-b467-22a14b4cd7fb",
   "metadata": {},
   "source": [
    "- Split between training and test set **1 point**\n",
    "\n",
    "_Note_: Use as parameters for splitting: `test_size=0.2`, `random_state=39`, `shuffle=True`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5898455-ac15-4eb2-9d48-6c058f191131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "    X_class, y_class, test_size=0.2, random_state=39, shuffle=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ea3208e-e021-4e0e-90f8-f6c6eb81c02a",
   "metadata": {},
   "source": [
    "- Rescale your features using `StandardScaler` **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b4cb5-1656-4353-8639-5a8a378f5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining the standard scaler\n",
    "standard_scaler = StandardScaler\n",
    "\n",
    "# Using the previous created function to scale our data\n",
    "X_train_class, X_test_class = get_scaler(\n",
    "    X_train_class, X_test_class, standard_scaler)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1a78d5a-7e57-49a3-8f15-7fa6f15e5027",
   "metadata": {},
   "source": [
    "### Question 8: Logistic Regression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe653332-9ff8-4ad6-a5ab-4e438a7d4f14",
   "metadata": {},
   "source": [
    "- Build and train a logistic regression classifier, using as parameters `penalty='l2'`, `solver='lbfgs'`, `max_iter=1000` **1 point**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92f70d1f",
   "metadata": {},
   "source": [
    "Just to clarify and note down what we are trying to do, we are using the Sigmoid function to predict our outcome : water safety.\n",
    "\n",
    "This prediction can be defined by the following equation:\n",
    "\\begin{align*}\n",
    "WaterSafety[0|1] = &\\ w_0 + w_{i/0} \\times[features] + \\epsilon_i\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "And using the Sigmoid function we bound our result between $[0,1]$:\n",
    "$$S(WaterSafety) = \\frac{1}{1 + e^{-WaterSafety}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cadc026-ffb9-4aea-b541-674127da7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting up logistic model\n",
    "logistic_model = LogisticRegression(\n",
    "    penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Fitting model\n",
    "logistic_model.fit(X_train_class, y_train_class)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4cb3a09-4c5e-4e89-84fe-aedfe7df7fc1",
   "metadata": {},
   "source": [
    "- Compute the accuracy on the training and test set. Compare it to the default rate. **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae9010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a pretty table\n",
    "\n",
    "def get_pretty_table(names, rows):\n",
    "    '''\n",
    "    Function that return a prettytable, with the given name for titles and rows\n",
    "    '''\n",
    "    table = pt.PrettyTable()\n",
    "    table.field_names = names\n",
    "\n",
    "    for row in rows:\n",
    "        table.add_row(row)\n",
    "\n",
    "    # Add borders to the table\n",
    "    table.hrules = pt.ALL\n",
    "    table.header = True\n",
    "    table.set_style(pt.SINGLE_BORDER)\n",
    "\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a716618f-ed45-49d1-8f86-fb000e7304ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Accuracy on the test set\n",
    "train_score = logistic_model.score(X_train_class, y_train_class)\n",
    "test_score = logistic_model.score(X_test_class, y_test_class)\n",
    "\n",
    "# Calculating default rate\n",
    "quality_0 = water_df.loc[water_df[outcome_q7] == 0].shape[0]\n",
    "quality_1 = water_df.loc[water_df[outcome_q7] == 1].shape[0]\n",
    "default_rate = max(quality_0, quality_1)/water_df.shape[0]\n",
    "\n",
    "# Using the get_pretty_table function to print in a nice way\n",
    "print(get_pretty_table(['Logistic Regression Metrics', 'Values'],\n",
    "                       [['Accuracy of Logistic regression classifier (training)', round(train_score, 3)],\n",
    "                       ['Accuracy of Logistic regression classifier (test)', round(test_score, 3)],\n",
    "                        ['Default rate', round(default_rate, 3)]\n",
    "                        ]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ed73329",
   "metadata": {},
   "source": [
    "We can see that we are a little above the default rate. We perform a bit better than guessing unsafe all the time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e70c2ae2-4659-4ae0-a79a-504b3c76443f",
   "metadata": {},
   "source": [
    "- Plot a heatmap of the confusion matrix. Class 1 is the positive class. How many false positive did we obtain? **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b64ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicting based on our trained logistic model\n",
    "pred_class = logistic_model.predict(X_test_class)\n",
    "\n",
    "# Use previous function to get heatmap\n",
    "get_heatmap(confusion_matrix(y_test_class, pred_class), title='Confusion Matrix Logistic Regression', color='Blues', vmin=confusion_matrix(\n",
    "    y_test_class, pred_class).min(), vmax=confusion_matrix(y_test_class, pred_class).max())\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_class, pred_class).ravel()\n",
    "print(f'False positives: {fp}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "187332b3",
   "metadata": {},
   "source": [
    "We got 19 false positives."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8755d13-e60d-47a0-8f1b-da6533c7d09a",
   "metadata": {},
   "source": [
    "- What is the precision, recall, and f1 score of class 1? Interpret the result. **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534e8c8-e260-44a5-a919-87a2b5766ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prec_rec_f1(pred, y_test) -> tuple[float]:\n",
    "    '''\n",
    "    Function that returns the Precision, Recall and F1-score\n",
    "    of the given predicted y-values values and  actual y values with the given model\n",
    "    '''\n",
    "    prec = precision_score(y_test, pred, zero_division=1)\n",
    "    rec = recall_score(y_test, pred, zero_division=1)\n",
    "    f1 = f1_score(y_test, pred, zero_division=1)\n",
    "    return prec, rec, f1\n",
    "\n",
    "\n",
    "def get_prec_rec_f1_df(X_train, X_test, y_train, y_test, model, column_name) -> pd.DataFrame:\n",
    "    '''\n",
    "    Function that returns a dataframe with the key performance features on training and test set\n",
    "    '''\n",
    "    # Predicting based on given model. Makes the function more dynamic\n",
    "    pred = model.predict(X_test_class)\n",
    "\n",
    "    # Accuracy on the test set\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    # Getting performance\n",
    "    prec, rec, f1 = get_prec_rec_f1(\n",
    "        pred=pred, y_test=y_test)\n",
    "\n",
    "    # Setting generic labels\n",
    "    perf_tests_labels = ['Accuracy Training',\n",
    "                         'Accuracy Test',\n",
    "                         'Precision (Class 1)',\n",
    "                         'Recall (Class 1)',\n",
    "                         'F1-score (Class 1)']\n",
    "\n",
    "    # Putting together dataframe\n",
    "    df = pd.DataFrame([train_score, test_score, prec, rec, f1],\n",
    "                      index=perf_tests_labels,\n",
    "                      columns=[column_name])\n",
    "\n",
    "    df = df.apply(lambda x: round(x, 3))\n",
    "    return df\n",
    "\n",
    "# Now we can use the function created to get all the performance metrics we want\n",
    "perf_logistic_df = get_prec_rec_f1_df(X_train_class, X_test_class, y_train_class,y_test_class, logistic_model, 'Logistic Model Performance')\n",
    "display(perf_logistic_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20e7318e",
   "metadata": {},
   "source": [
    "Reminder that;\n",
    "$$Precision = \\frac{TP}{TP+FP}, \\quad Recall=\\frac{TP}{TP+FN}, \\quad and \\quad F1 = 2 \\frac{{Precision}\\cdot{Recall}}{Precision+Recall}$$\n",
    "\n",
    "With a precision at ~$70$% we predicted correctly when we predicted Class 1 ~70% of the time. Meaning the fraction of correct predicted positives over total positive prediction.  With a recall of $30$%, we are only correctly predicting the safe water ~$30$% of the time. Which means that out of the actual safe water, we predict safe water to be unsafe ~$70$% of the time. The $\\text{F1 Score}$ is bounded in the interval $[0,1]$, where 1 means perfect precision and recall, which is low and indicates that the model is not performing well on the positive class. Which we can argue is ok, since it's unsafe water quality that is the most important thing to be good at. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be0dd998-c956-4728-9075-34cb13eeee1e",
   "metadata": {},
   "source": [
    "- Build and train a logistic regression classifier with cross-validation, using 5 folds **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345bab1-5985-401f-8141-f01198cb1028",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logistic_model_cv = LogisticRegressionCV(penalty='l2', solver='lbfgs', cv=5, max_iter=1000)\n",
    "logistic_model_cv.fit(X_train_class, y_train_class)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f89355fb-1030-41d4-9d60-5c804f28ad54",
   "metadata": {},
   "source": [
    "- Plot a heatmap of the confusion matrix. Compute the accuracy on the training and test set; as well as the precision, recall, and f1 score of class 1. How do your metrics compare to your model without cross-validation? **1 point**\n",
    "\n",
    "_Note_: You can, but not have to, create a function to calculate your evaluation metrics since we will perform the same operation later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa9de8-956e-45a2-b3fe-a798b1bf93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting based on our trained logistic CV model\n",
    "pred_class_cv = logistic_model_cv.predict(X_test_class)\n",
    "\n",
    "get_heatmap(confusion_matrix(y_test_class, pred_class_cv), title='Confusion Matrix CV Model', color='Blues', vmin=confusion_matrix(\n",
    "    y_test_class, pred_class_cv).min(), vmax=confusion_matrix(y_test_class, pred_class_cv).max())\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da45ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we can re-use the function previously created\n",
    "perf_cv_df = get_prec_rec_f1_df(X_train_class, X_test_class, y_train_class,\n",
    "                                y_test_class, logistic_model_cv, 'Logistic CV Model Performance')\n",
    "\n",
    "perf_comparison_df = perf_logistic_df.copy()\n",
    "perf_comparison_df[perf_cv_df.columns[0]] = perf_cv_df\n",
    "perf_comparison_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41b2b43d",
   "metadata": {},
   "source": [
    "We can see that the CV model does not perform better than the normal logistic model. The same happens here. To not repeat myself by this could be due to the imbalanced nature of the dataset, where Class 1 has very few samples compared to Class 0. Which is exactly what we saw earlier. The training-set only includes $0.2 * 91+ =  182$ \"good water-quality\" observations, making the model bad a predicting good water. Thus the model could be biased towards predicting Class 0 (unsafe) more often. Additionally, we can see from the correlation matrix heatmap that each individual feature does not have a huge correlation with the water safety. This could also impact our results. And as mentioned, the precision is more important than recall. But again, when it comes to drinking water it's better to be safe than sorry, even tough a more balanced dataset would make it easier to distinguish the two categories. Moreover, CV might not give us any better performance since we have a total of 8000 observations and the shuffle makes the sets we use to train our model representative, hence CV does not help. Even more, if the relationship is non-linear, logistic regression is not the right algorithm to solve this problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59c37554-92a3-44b3-83ec-39fd76a16b39",
   "metadata": {},
   "source": [
    "### Question 9: KNN classifier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e829a37-268e-4310-9b51-d868020e1488",
   "metadata": {},
   "source": [
    "- Build and train a KNN classifier with parameters `n_neighbors=7`, `p=2`, `weights='uniform'` **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead0216-3239-4a1b-9bc3-00f8601628a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Copying train and test set from previous exercise\n",
    "X_train_knn, X_test_knn, y_train_knn, y_test_knn = X_train_class, X_test_class, y_train_class, y_test_class\n",
    "\n",
    "# Setting up the model, weights='uniform' is default\n",
    "model_kNN = KNeighborsClassifier(n_neighbors=7, p=2)\n",
    "\n",
    "# Fit our model\n",
    "model_kNN.fit(X_train_knn, y_train_knn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b09b651-b03a-4cfc-b514-a823c6914ca5",
   "metadata": {},
   "source": [
    "- Plot a heatmap of the confusion matrix. Compute the accuracy on the training and test set; as well as the precision, recall, and f1 score of class 1. How do your metrics compare to your previous models? **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9accce5-d52d-44f4-a006-8b4b1f4885f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting based on our trained KNN model\n",
    "pred_knn = model_kNN.predict(X_test_knn)\n",
    "\n",
    "get_heatmap(confusion_matrix(y_test_knn, pred_knn), title='Confusion Matrix KNN Model', color='Blues', vmin=confusion_matrix(\n",
    "    y_test_knn, pred_knn).min(), vmax=confusion_matrix(y_test_knn, pred_knn).max())\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()\n",
    "\n",
    "# Getting performance metrics\n",
    "perf_knn_df = get_prec_rec_f1_df(X_train_knn, X_test_knn, y_train_knn,y_test_knn, model_kNN, 'KNN Model Performance')\n",
    "\n",
    "perf_knn_comparison_df = perf_comparison_df.copy()\n",
    "perf_knn_comparison_df[perf_knn_df.columns[0]] = perf_knn_df\n",
    "display(perf_knn_comparison_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53eb0f7a",
   "metadata": {},
   "source": [
    "Conclusion **before removing the negative values for ammonia**: We clearly see here that the KNN model performs poorly. This could be due to the fact that the KNN model is not sophisticated enough to capture the relationship between our features and the outcome. It might also bee that the KNN model handles the imbalanced data worse than our logistic models. So it could suggest that the decision boundary between the two classes is not highly dependent on the distance/proximity of the nearest neighbors in the feature-dimensional space...\n",
    "\n",
    "**New conclusion** the KNN model performs a bit better than our Logistic Model. It was cool to see that removing 10 negative variables could have such a huge impact. Since we are using the scaler, our values goes from [-1,1] so it's not the fact that they where negative, but they where probably wrong. The nearest neighbor with euclidean distance was really punished by these wrong datapoints. The KNN algorithm could be better as well due to the fact that in handles non-linearity better than logistic regression.  (Previously i had (negative ammonia) a precision and recall around 0.4). Note to self: Check your data!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63b12db0-a203-4c0e-8976-7e4035a6ea8e",
   "metadata": {},
   "source": [
    "- Use `GridSearchCV` to explore different parameters for your model: `n_neighbors` between 1 and 11, `p` between 1 and 3, and `weights` either 'uniform' or 'distance' **1 point**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12a10856",
   "metadata": {},
   "source": [
    "I assume that when it's written between:\n",
    "\n",
    "- \"Between 1 and 11\" = [1,10] = [1,2,3,4,5,6,8,9,10]\n",
    "- \"Between 1 and 3\" = [1,2] = [1,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99ee6b-c812-4672-9ce5-a98c79a25c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining ranges\n",
    "neighbors = np.arange(1, 11)\n",
    "p = np.arange(1, 3)\n",
    "\n",
    "grid = {'n_neighbors': neighbors,\n",
    "        'p': p,\n",
    "        'weights': ['uniform', 'distance']   # weights\n",
    "        }\n",
    "\n",
    "# Defining and fit model with optimal\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, grid, cv=10)\n",
    "knn_cv.fit(X_train_knn, y_train_knn)\n",
    "\n",
    "# Printing results\n",
    "print(\"Hyperparameters: \", knn_cv.best_params_)\n",
    "print(\"Train Score: {:0.2f}\".format(knn_cv.best_score_))\n",
    "print(\"Test Score: {:0.2f}\".format(knn_cv.score(X_test_knn, y_test_knn)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aef17736-e4de-477a-9a08-ac5afa8cb29f",
   "metadata": {},
   "source": [
    "- For your 'optimal' model, compute the accuracy on the training and test set; as well as the precision, recall, and f1 score of class 1. How do your metrics compare to your previous models? **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5e182-ecd4-4bba-8605-5a27df95ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our model\n",
    "model_kNN_optimal = KNeighborsClassifier(n_neighbors=9, p=2)\n",
    "\n",
    "# Fit our model\n",
    "model_kNN_optimal.fit(X_train_knn, y_train_knn)\n",
    "\n",
    "perf_knn_df = get_prec_rec_f1_df(X_train_knn, X_test_knn, y_train_knn,\n",
    "                                 y_test_knn, model_kNN_optimal, 'Optimal KNN Model Performance')\n",
    "\n",
    "\n",
    "perf_knn_comparison_df[perf_knn_df.columns[0]] = perf_knn_df\n",
    "display(perf_knn_comparison_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab21d53e",
   "metadata": {},
   "source": [
    "We can see that the model does not really change. Maybe a slight improvement in Precision. Still performing better than the logistic models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45dc258a-d7cb-46da-a8cb-c3749a6bbe03",
   "metadata": {},
   "source": [
    "### Question 10: Decision Trees\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b267fafa-a5b4-4759-a6ec-9b95ef00e3ff",
   "metadata": {},
   "source": [
    "- Build and train a Decision Tree with parameters `criterion = 'gini'`, `max_depth = 3` **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce7ca3-5d8a-4e8a-b1b2-f310847373fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Now with decision tree we don't need the scaled data, DT can even handle categorical data\n",
    "X_train_tree, X_test_tree, y_train_tree, y_test_tree = train_test_split(\n",
    "    X_class, y_class, test_size=0.2, random_state=39, shuffle=True)\n",
    "\n",
    "# Copying train and test set from previous exercise to keep things clean\n",
    "X_train_tree, X_test_tree, y_train_tree, y_test_tree = X_train_class, X_test_class, y_train_class, y_test_class\n",
    "\n",
    "\n",
    "\n",
    "# Create model\n",
    "model_tree = DecisionTreeClassifier(criterion='gini', max_depth=3)\n",
    "\n",
    "# Fit model\n",
    "model_tree.fit(X_train_tree, y_train_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "541e86cf",
   "metadata": {},
   "source": [
    "I tested the three with both scaled and not scaled data, the latter had 1% better recall for the optimal solution. Otherwise they where almost identical. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e154e70d-e2b8-4a8b-b6f6-a53ddbfba37d",
   "metadata": {},
   "source": [
    "- Plot a heatmap of the confusion matrix. Compute the accuracy on the training and test set; as well as the precision, recall, and f1 score of class 1. How do your metrics compare to your previous models? **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1997aca-cbf3-4a23-bf65-bcdd15293d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicting based on our trained Decision Tree\n",
    "pred_tree = model_tree.predict(X_test_tree)\n",
    "\n",
    "get_heatmap(confusion_matrix(y_test_knn, pred_tree), title='Confusion Matrix Decision Tree', color='Blues', vmin=confusion_matrix(\n",
    "    y_test_tree, pred_tree).min(), vmax=confusion_matrix(y_test_tree, pred_tree).max())\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()\n",
    "\n",
    "# Getting performance metrics\n",
    "perf_tree_df = get_prec_rec_f1_df(\n",
    "    X_train_tree, X_test_tree, y_train_tree, y_test_tree, model_tree, 'Decision Tree Performance')\n",
    "\n",
    "all_comparison = perf_knn_comparison_df.copy()\n",
    "\n",
    "all_comparison[perf_tree_df.columns[0]] = perf_tree_df\n",
    "display(all_comparison)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e01c75b9",
   "metadata": {},
   "source": [
    "The decision tree performs even better than the previous models! First model with a precision over 90%. We have a quite large set of features, which could favour the decision tree over KNN and Logistic regression. The Decision tree can capture nonlinear relationships between the features and the target variable. On the other side, logistic regression assumes that this relationship is linear."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cc151dd-9582-4c76-bde6-4d9a0dea9c11",
   "metadata": {},
   "source": [
    "- Visualize your Decision Tree **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e817f98-e0e1-4753-8a00-a81f545a93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating figure\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(model_tree, filled=True,\n",
    "          feature_names=features_classification, fontsize=12, rounded=True)\n",
    "\n",
    "# Setting some labels\n",
    "plt.title(\"Decision Tree Classifier\", fontsize=20)\n",
    "plt.xlabel(\"Features\", fontsize=16)\n",
    "plt.ylabel(\"Target Variable\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aacfc59f-7aa0-4030-9ef0-58a051be89e7",
   "metadata": {},
   "source": [
    "- Use `GridSearchCV` to explore different parameters for your model: `criterion` either 'gini' or 'entropy' and `max_depth` between 1 and 7 **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab96a6-d754-4e5b-9e8c-f756760a2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to test\n",
    "grid_tree = {'criterion': ['gini', 'entropy'], 'max_depth': np.arange(1, 8)}\n",
    "\n",
    "# Define and fit model\n",
    "tree_class = DecisionTreeClassifier()\n",
    "tree_class_cv = GridSearchCV(tree_class, grid_tree, cv=5)\n",
    "tree_class_cv.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "# Print results\n",
    "print(\"Best model:\", tree_class_cv.best_estimator_)\n",
    "print(\"Train Score: {:0.2f}\".format(tree_class_cv.best_score_))\n",
    "print(\"Test Score: {:0.2f}\".format(tree_class_cv.score(X_test_tree, y_test_tree)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "daf7a522-280b-4cc1-8893-81ae00092957",
   "metadata": {},
   "source": [
    "- For your 'optimal' model, compute the accuracy on the training and test set; as well as the precision, recall, and f1 score of class 1. How do your metrics compare to your previous models? **1 point**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57ad79-6c5d-4385-8b36-7141cf54801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_tree_optimal = DecisionTreeClassifier(criterion='entropy', max_depth=7)\n",
    "\n",
    "# Fit model\n",
    "model_tree_optimal.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "# Predicting based on our trained Decision Tree\n",
    "pred_tree_optimal = model_tree_optimal.predict(X_test_tree)\n",
    "\n",
    "get_heatmap(confusion_matrix(y_test_knn, pred_tree_optimal), title='Confusion Matrix Optimal Decision Tree', color='Blues', vmin=confusion_matrix(\n",
    "    y_test_tree, pred_tree).min(), vmax=confusion_matrix(y_test_tree, pred_tree_optimal).max())\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()\n",
    "\n",
    "# Getting performance metrics\n",
    "perf_tree_optimal_df = get_prec_rec_f1_df(\n",
    "    X_train_tree, X_test_tree, y_train_tree, y_test_tree, model_tree_optimal, 'Optimal Decision Tree Performance')\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_knn, pred_tree_optimal).ravel()\n",
    "\n",
    "print(f'\\nTrue Negatives: {tn}\\\n",
    "        \\nFalse Negatives: {fn}\\\n",
    "        \\nFalse Positives: {fp}\\\n",
    "        True Positives: {tp}')\n",
    "\n",
    "all_comparison[perf_tree_optimal_df.columns[0]] = perf_tree_optimal_df\n",
    "display(all_comparison)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af115d1d",
   "metadata": {},
   "source": [
    "Best accuracy on training set so far, and almost the same precision as the previous decision tree. But not the lowest false positive which might be what we really care about in this case which is related to how many times have we told people that the water is safe, but it's actually not. Overall the decisions tree performed well! Well suited for a lot of features with a complex relation to the outcome variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbc3b538-551c-4098-b82f-8c00d976a448",
   "metadata": {},
   "source": [
    "Congrats, you are done with the assignment!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p pandas,numpy,sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
